{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import scipy.io as sio\n",
    "import requests\n",
    "from keras.callbacks import TensorBoard, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Feb 14 23:48:59 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.4985903 , 0.44685881, 0.49161327, ..., 0.49999913, 0.49999922,\n",
       "         0.49999928],\n",
       "        [0.48090509, 0.51376038, 0.521272  , ..., 0.49930221, 0.49933539,\n",
       "         0.49936612],\n",
       "        [0.43273326, 0.58984117, 0.52738918, ..., 0.5005054 , 0.50048927,\n",
       "         0.5004741 ],\n",
       "        ...,\n",
       "        [0.4461623 , 0.51513364, 0.49219537, ..., 0.49981382, 0.49981551,\n",
       "         0.49981708],\n",
       "        [0.50241332, 0.56350649, 0.49639131, ..., 0.50008163, 0.50008288,\n",
       "         0.50008405],\n",
       "        [0.46047434, 0.18466446, 0.55279766, ..., 0.49946052, 0.4994818 ,\n",
       "         0.49950172]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Htrainin.mat\")\n",
    "train_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__header__', '__version__', '__globals__', 'HT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(train_mat_file.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Thu Feb 15 15:15:44 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.26092366, 0.85190529, 0.60494775, ..., 0.50036418, 0.50035066,\n",
       "         0.50033798],\n",
       "        [0.33303705, 0.55504731, 0.52144482, ..., 0.49960132, 0.49962547,\n",
       "         0.49964788],\n",
       "        [0.4888583 , 0.24057908, 0.51233443, ..., 0.50040599, 0.50040003,\n",
       "         0.50039445],\n",
       "        ...,\n",
       "        [0.48810183, 0.33112218, 0.51703999, ..., 0.50035488, 0.50034619,\n",
       "         0.50033811],\n",
       "        [0.55198378, 0.34518412, 0.47276785, ..., 0.49952237, 0.49954685,\n",
       "         0.49956975],\n",
       "        [0.49810788, 0.49417168, 0.50562409, ..., 0.49978085, 0.4997903 ,\n",
       "         0.49979911]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Htestin.mat\")\n",
    "test_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Thu Feb 15 12:25:52 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.52056352, 0.46953018, 0.48859902, ..., 0.49981154, 0.49982013,\n",
       "         0.49982817],\n",
       "        [0.62065814, 0.30577164, 0.43289641, ..., 0.49939754, 0.49933464,\n",
       "         0.49927567],\n",
       "        [0.50879717, 0.52795825, 0.46545486, ..., 0.49941865, 0.49946489,\n",
       "         0.49950812],\n",
       "        ...,\n",
       "        [0.55270157, 0.0092473 , 0.4575696 , ..., 0.49937621, 0.49939926,\n",
       "         0.49942082],\n",
       "        [0.50073979, 0.49842314, 0.49969159, ..., 0.50002873, 0.50002719,\n",
       "         0.50002578],\n",
       "        [0.53566402, 0.45551388, 0.52186067, ..., 0.49834792, 0.49843517,\n",
       "         0.49851627]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Hvalin.mat\")\n",
    "val_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_mat_file[\"HT\"]\n",
    "x_test = test_mat_file[\"HT\"]\n",
    "x_val = val_mat_file[\"HT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2048)\n",
      "(20000, 2048)\n",
      "(30000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "x_val = x_val.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channels = 2\n",
    "total = height*width*channels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = 2\n",
    "encoded_dim = 512\n",
    "initial_lr = 5e-3\n",
    "lr_drop_period = 100\n",
    "lr_drop_factor = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x, residual, encoded_dim):\n",
    "    def addcommonlayers(y):\n",
    "        y = BatchNormalization()(y)\n",
    "        y = LeakyReLU()(y)\n",
    "        return y\n",
    "    \n",
    "    def decoded(y):\n",
    "        temp = y\n",
    "        y = Conv2D(8, kernel_size=(3,3),padding = 'same' )(y)\n",
    "        y = addcommonlayers(y)\n",
    "        \n",
    "        y = Conv2D(16, kernel_size = (3,3),padding = 'same')(y)\n",
    "        y = addcommonlayers(y)\n",
    "\n",
    "        y = Conv2D(2,kernel_size = (3,3),padding = 'same')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = add([temp,y])\n",
    "        y = LeakyReLU()(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    x = Conv2D(2,(3,3),padding = 'same')(x)\n",
    "    x = addcommonlayers(x)\n",
    "\n",
    "    x = Reshape((total,))(x)\n",
    "    encoded = Dense(encoded_dim, activation = 'linear')(x)\n",
    "\n",
    "    x = Dense(total,activation='linear')(x)\n",
    "    x = Reshape((height,width,channels))(x)\n",
    "\n",
    "    for i in range(residual):\n",
    "        x = decoded(x)\n",
    "\n",
    "    x = Conv2D(2,(3,3),activation = 'sigmoid',padding = 'same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 2)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 2)   8           ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 32, 2)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048)         0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2048)         4196352     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 32, 32, 2)    0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 8)    152         ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 8)   32          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 8)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   1168        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 2)    290         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 2)   8           ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 2)    0           ['reshape_1[0][0]',              \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32, 32, 2)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 8)    152         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 8)   32          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 32, 32, 8)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   1168        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 2)    290         ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 2)   8           ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 2)    0           ['leaky_re_lu_3[0][0]',          \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 32, 32, 2)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 2)    38          ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,199,864\n",
      "Trainable params: 4,199,756\n",
      "Non-trainable params: 108\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "image_tensor = Input(shape=(height,width,channels))\n",
    "network_output = network(image_tensor, residual, encoded_dim)\n",
    "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), channels, height, width))\n",
    "x_train = np.transpose(x_train, (0,2,3,1)) # remove this line if using `channels_first` image data format \n",
    "x_val = np.reshape(x_val, (len(x_val), channels, height, width))\n",
    "x_val = np.transpose(x_val, (0,2,3,1)) # remove this line if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), channels, height, width))\n",
    "x_test = np.transpose(x_test, (0,2,3,1)) # remove this line if using `channels_first` i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses_train = []\n",
    "        self.losses_val = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses_train.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses_val.append(logs.get('val_loss'))\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        if lr_drop_period == np.Inf or np.mod(epoch,lr_drop_period) != 0:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-lr_drop_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = LossHistory()\n",
    "file = 'CsiNet_'+'_dim'+str(encoded_dim)+time.strftime('_%m_%d')\n",
    "path = 'result/TensorBoard_%s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=200,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 68/500 [===>..........................] - ETA: 9:09 - loss: 0.0028"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[history,\n",
    "                           TensorBoard(log_dir = path), earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result/trainloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_train)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result/valloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_val)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 59s 76ms/step\n",
      "It cost 0.003372 sec\n"
     ]
    }
   ],
   "source": [
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(x_i,x_hat):\n",
    "    x_i_real = np.reshape(x_i[:,:,:,0],(len(x_i),-1))\n",
    "    x_i_img  = np.reshape(x_i[:,:,:,1],(len(x_i),-1))\n",
    "    x_i_C = x_i_real-0.5 + 1j*(x_i_img-0.5)\n",
    "\n",
    "    x_hat_real = np.reshape(x_i[:,:,:,0],(len(x_i),-1))\n",
    "    x_hat_img  = np.reshape(x_i[:,:,:,1],(len(x_i),-1))\n",
    "    x_hat_C = x_hat_real-0.5 + 1j*(x_hat_img-0.5)\n",
    "\n",
    "    mse = np.sum(abs(x_i_C-x_hat_C)**2, axis=1)\n",
    "    power = np.sum(abs(x_i_C)**2, axis=1)\n",
    "    NMSE = 10*math.log10(np.mean(mse/power))\n",
    "\n",
    "    return NMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\jupyter vs\\Model 1.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNMSE is \u001b[39m\u001b[39m\"\u001b[39m, NMSE(x_test,x_hat))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresult/decoded_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39mfile\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_hat1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(x_hat, (\u001b[39mlen\u001b[39m(x_hat), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"NMSE is \", NMSE(x_test,x_hat))\n",
    "filename = \"result/decoded_%s.csv\"%file\n",
    "x_hat1 = np.reshape(x_hat, (len(x_hat), -1))\n",
    "np.savetxt(filename, x_hat1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\jupyter vs\\Model 1.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Serialize model to JSON\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_json \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mto_json()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m outfile \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresult/model_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39mfile\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/jupyter%20vs/Model%201.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(outfile, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Serialize model to JSON\n",
    "model_json = autoencoder.to_json()\n",
    "outfile = \"result/model_%s.json\"%file\n",
    "with open(outfile, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Serialize weights to HDF5\n",
    "outfile = \"result/model_%s.h5\"%file\n",
    "autoencoder.save_weights(outfile)\n",
    "\n",
    "# Save model in tensorflow format\n",
    "autoencoder.save(\"tensorflow/model_%s\"%file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
