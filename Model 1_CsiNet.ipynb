{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np #importing numpy\n",
    "import pandas as pd #importing pandas\n",
    "import tensorflow as tf #importing tensorflow\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU #importing different types of layers from keras.layers\n",
    "from keras.models import Model #importing Model from keras.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import scipy.io as sio\n",
    "import requests\n",
    "from keras.callbacks import TensorBoard, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Feb 14 23:48:59 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.4985903 , 0.44685881, 0.49161327, ..., 0.49999913, 0.49999922,\n",
       "         0.49999928],\n",
       "        [0.48090509, 0.51376038, 0.521272  , ..., 0.49930221, 0.49933539,\n",
       "         0.49936612],\n",
       "        [0.43273326, 0.58984117, 0.52738918, ..., 0.5005054 , 0.50048927,\n",
       "         0.5004741 ],\n",
       "        ...,\n",
       "        [0.4461623 , 0.51513364, 0.49219537, ..., 0.49981382, 0.49981551,\n",
       "         0.49981708],\n",
       "        [0.50241332, 0.56350649, 0.49639131, ..., 0.50008163, 0.50008288,\n",
       "         0.50008405],\n",
       "        [0.46047434, 0.18466446, 0.55279766, ..., 0.49946052, 0.4994818 ,\n",
       "         0.49950172]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Htrainin.mat\")\n",
    "train_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__header__', '__version__', '__globals__', 'HT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(train_mat_file.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Thu Feb 15 15:15:44 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.26092366, 0.85190529, 0.60494775, ..., 0.50036418, 0.50035066,\n",
       "         0.50033798],\n",
       "        [0.33303705, 0.55504731, 0.52144482, ..., 0.49960132, 0.49962547,\n",
       "         0.49964788],\n",
       "        [0.4888583 , 0.24057908, 0.51233443, ..., 0.50040599, 0.50040003,\n",
       "         0.50039445],\n",
       "        ...,\n",
       "        [0.48810183, 0.33112218, 0.51703999, ..., 0.50035488, 0.50034619,\n",
       "         0.50033811],\n",
       "        [0.55198378, 0.34518412, 0.47276785, ..., 0.49952237, 0.49954685,\n",
       "         0.49956975],\n",
       "        [0.49810788, 0.49417168, 0.50562409, ..., 0.49978085, 0.4997903 ,\n",
       "         0.49979911]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Htestin.mat\")\n",
    "test_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Thu Feb 15 12:25:52 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'HT': array([[0.52056352, 0.46953018, 0.48859902, ..., 0.49981154, 0.49982013,\n",
       "         0.49982817],\n",
       "        [0.62065814, 0.30577164, 0.43289641, ..., 0.49939754, 0.49933464,\n",
       "         0.49927567],\n",
       "        [0.50879717, 0.52795825, 0.46545486, ..., 0.49941865, 0.49946489,\n",
       "         0.49950812],\n",
       "        ...,\n",
       "        [0.55270157, 0.0092473 , 0.4575696 , ..., 0.49937621, 0.49939926,\n",
       "         0.49942082],\n",
       "        [0.50073979, 0.49842314, 0.49969159, ..., 0.50002873, 0.50002719,\n",
       "         0.50002578],\n",
       "        [0.53566402, 0.45551388, 0.52186067, ..., 0.49834792, 0.49843517,\n",
       "         0.49851627]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mat_file = sio.loadmat(\"D:\\SURGE2023\\DATA_Hvalin.mat\")\n",
    "val_mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_mat_file[\"HT\"]\n",
    "x_test = test_mat_file[\"HT\"]\n",
    "x_val = val_mat_file[\"HT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2048)\n",
      "(20000, 2048)\n",
      "(30000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "x_val = x_val.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channels = 2\n",
    "total = height*width*channels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = 2\n",
    "encoded_dim = 512\n",
    "initial_lr = 5e-3\n",
    "lr_drop_period = 100\n",
    "lr_drop_factor = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x, residual, encoded_dim):\n",
    "    def addcommonlayers(y):\n",
    "        y = BatchNormalization()(y)\n",
    "        y = LeakyReLU()(y)\n",
    "        return y\n",
    "    \n",
    "    def decoded(y):\n",
    "        temp = y\n",
    "        y = Conv2D(8, kernel_size=(3,3),padding = 'same' )(y)\n",
    "        y = addcommonlayers(y)\n",
    "        \n",
    "        y = Conv2D(16, kernel_size = (3,3),padding = 'same')(y)\n",
    "        y = addcommonlayers(y)\n",
    "\n",
    "        y = Conv2D(2,kernel_size = (3,3),padding = 'same')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = add([temp,y])\n",
    "        y = LeakyReLU()(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    x = Conv2D(2,(3,3),padding = 'same')(x)\n",
    "    x = addcommonlayers(x)\n",
    "\n",
    "    x = Reshape((total,))(x)\n",
    "    encoded = Dense(encoded_dim, activation = 'linear')(x)\n",
    "\n",
    "    x = Dense(total,activation='linear')(x)\n",
    "    x = Reshape((height,width,channels))(x)\n",
    "\n",
    "    for i in range(residual):\n",
    "        x = decoded(x)\n",
    "\n",
    "    x = Conv2D(2,(3,3),activation = 'sigmoid',padding = 'same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 2)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 2)   8           ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 32, 2)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048)         0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2048)         4196352     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 32, 32, 2)    0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 8)    152         ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 8)   32          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 8)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   1168        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 2)    290         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 2)   8           ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 2)    0           ['reshape_1[0][0]',              \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32, 32, 2)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 8)    152         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 8)   32          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 32, 32, 8)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   1168        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 2)    290         ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 2)   8           ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 2)    0           ['leaky_re_lu_3[0][0]',          \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 32, 32, 2)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 2)    38          ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,199,864\n",
      "Trainable params: 4,199,756\n",
      "Non-trainable params: 108\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "image_tensor = Input(shape=(height,width,channels))\n",
    "network_output = network(image_tensor, residual, encoded_dim)\n",
    "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), channels, height, width))\n",
    "x_train = np.transpose(x_train, (0,2,3,1)) # remove this line if using `channels_first` image data format \n",
    "x_val = np.reshape(x_val, (len(x_val), channels, height, width))\n",
    "x_val = np.transpose(x_val, (0,2,3,1)) # remove this line if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), channels, height, width))\n",
    "x_test = np.transpose(x_test, (0,2,3,1)) # remove this line if using `channels_first` i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses_train = []\n",
    "        self.losses_val = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses_train.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses_val.append(logs.get('val_loss'))\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        if lr_drop_period == np.Inf or np.mod(epoch,lr_drop_period) != 0:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-lr_drop_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = LossHistory()\n",
    "file = 'CsiNet_'+'_dim'+str(encoded_dim)+time.strftime('_%m_%d')\n",
    "path = 'result/TensorBoard_%s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=200,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 720s 1s/step - loss: 7.1282e-04 - val_loss: 4.3538e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 449s 897ms/step - loss: 2.4128e-04 - val_loss: 0.0340\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1419s 3s/step - loss: 1.6957e-04 - val_loss: 3.0796e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 442s 883ms/step - loss: 1.3455e-04 - val_loss: 0.0541\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 440s 879ms/step - loss: 1.1104e-04 - val_loss: 7.5473e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 439s 878ms/step - loss: 1.0605e-04 - val_loss: 0.0418\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 671s 1s/step - loss: 9.4285e-05 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 584s 1s/step - loss: 8.5542e-05 - val_loss: 2.7708e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 442s 885ms/step - loss: 7.4290e-05 - val_loss: 1.4577e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 439s 879ms/step - loss: 6.9048e-05 - val_loss: 8.1885e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c328841be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[history,\n",
    "                           TensorBoard(log_dir = path), earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result/trainloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_train)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result/valloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_val)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 26s 41ms/step\n",
      "It cost 0.001605 sec\n"
     ]
    }
   ],
   "source": [
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.32546124, 0.27011594],\n",
       "         [0.8304058 , 0.8114788 ],\n",
       "         [0.5705308 , 0.6043475 ],\n",
       "         ...,\n",
       "         [0.50680053, 0.5057155 ],\n",
       "         [0.5085773 , 0.50607395],\n",
       "         [0.50178695, 0.49627075]],\n",
       "\n",
       "        [[0.5940764 , 0.5842896 ],\n",
       "         [0.44206798, 0.47386715],\n",
       "         [0.5060197 , 0.49213055],\n",
       "         ...,\n",
       "         [0.4991824 , 0.50473976],\n",
       "         [0.49007744, 0.4996711 ],\n",
       "         [0.50548   , 0.49842408]],\n",
       "\n",
       "        [[0.6579405 , 0.5206724 ],\n",
       "         [0.26405266, 0.40053877],\n",
       "         [0.420524  , 0.47141343],\n",
       "         ...,\n",
       "         [0.49564248, 0.5029201 ],\n",
       "         [0.4911952 , 0.50171936],\n",
       "         [0.5032571 , 0.49525535]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.48279542, 0.4737401 ],\n",
       "         [0.49904382, 0.5087365 ],\n",
       "         [0.49327132, 0.50682914],\n",
       "         ...,\n",
       "         [0.4988521 , 0.4981403 ],\n",
       "         [0.4982949 , 0.5034638 ],\n",
       "         [0.50422394, 0.49965367]],\n",
       "\n",
       "        [[0.51362365, 0.4802076 ],\n",
       "         [0.4936279 , 0.51500064],\n",
       "         [0.5007552 , 0.50376236],\n",
       "         ...,\n",
       "         [0.4973203 , 0.5070651 ],\n",
       "         [0.4965705 , 0.49809843],\n",
       "         [0.5025043 , 0.49846187]],\n",
       "\n",
       "        [[0.49720612, 0.48072582],\n",
       "         [0.497919  , 0.52961606],\n",
       "         [0.503351  , 0.48882246],\n",
       "         ...,\n",
       "         [0.49951634, 0.4974641 ],\n",
       "         [0.5020716 , 0.4944403 ],\n",
       "         [0.5022461 , 0.49786118]]],\n",
       "\n",
       "\n",
       "       [[[0.3668793 , 0.30786934],\n",
       "         [0.5920606 , 0.60252476],\n",
       "         [0.52445656, 0.5834803 ],\n",
       "         ...,\n",
       "         [0.5034879 , 0.50434494],\n",
       "         [0.5046454 , 0.5035154 ],\n",
       "         [0.5001935 , 0.4964281 ]],\n",
       "\n",
       "        [[0.5401442 , 0.5265012 ],\n",
       "         [0.50867295, 0.5416324 ],\n",
       "         [0.5305043 , 0.49539527],\n",
       "         ...,\n",
       "         [0.50162745, 0.5013926 ],\n",
       "         [0.49613017, 0.5028699 ],\n",
       "         [0.50203735, 0.49936897]],\n",
       "\n",
       "        [[0.501666  , 0.48161897],\n",
       "         [0.4865517 , 0.4932231 ],\n",
       "         [0.500019  , 0.49029326],\n",
       "         ...,\n",
       "         [0.4975118 , 0.5037373 ],\n",
       "         [0.4976771 , 0.50221527],\n",
       "         [0.5031164 , 0.49694282]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.54487914, 0.4866149 ],\n",
       "         [0.43108407, 0.49476117],\n",
       "         [0.48620284, 0.51428837],\n",
       "         ...,\n",
       "         [0.4982816 , 0.49629498],\n",
       "         [0.4996899 , 0.49800774],\n",
       "         [0.5022156 , 0.49899685]],\n",
       "\n",
       "        [[0.5468829 , 0.49756235],\n",
       "         [0.46944275, 0.5299159 ],\n",
       "         [0.4975392 , 0.49442914],\n",
       "         ...,\n",
       "         [0.49760658, 0.50362897],\n",
       "         [0.4954408 , 0.49990594],\n",
       "         [0.50328004, 0.49788132]],\n",
       "\n",
       "        [[0.5635059 , 0.51745844],\n",
       "         [0.50810146, 0.5212964 ],\n",
       "         [0.47551587, 0.48574457],\n",
       "         ...,\n",
       "         [0.49872908, 0.49855503],\n",
       "         [0.50110406, 0.49704584],\n",
       "         [0.5010583 , 0.4996245 ]]],\n",
       "\n",
       "\n",
       "       [[[0.55245364, 0.41249305],\n",
       "         [0.17273048, 0.3625998 ],\n",
       "         [0.5013945 , 0.5497328 ],\n",
       "         ...,\n",
       "         [0.4998395 , 0.4995653 ],\n",
       "         [0.499423  , 0.5010594 ],\n",
       "         [0.499085  , 0.50026697]],\n",
       "\n",
       "        [[0.52500683, 0.5340715 ],\n",
       "         [0.4699289 , 0.09654925],\n",
       "         [0.5297043 , 0.54675406],\n",
       "         ...,\n",
       "         [0.5021759 , 0.49803418],\n",
       "         [0.49749222, 0.4994937 ],\n",
       "         [0.50120807, 0.5013587 ]],\n",
       "\n",
       "        [[0.46574306, 0.44924998],\n",
       "         [0.47032297, 0.7671813 ],\n",
       "         [0.5033192 , 0.46678078],\n",
       "         ...,\n",
       "         [0.500235  , 0.49679366],\n",
       "         [0.50063324, 0.5014866 ],\n",
       "         [0.50037247, 0.4997211 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.48857072, 0.48915225],\n",
       "         [0.5501263 , 0.40812594],\n",
       "         [0.50322944, 0.509287  ],\n",
       "         ...,\n",
       "         [0.49885502, 0.4959567 ],\n",
       "         [0.49962926, 0.49924242],\n",
       "         [0.5013589 , 0.5000543 ]],\n",
       "\n",
       "        [[0.52899086, 0.48791853],\n",
       "         [0.5662917 , 0.40948945],\n",
       "         [0.47209626, 0.48902586],\n",
       "         ...,\n",
       "         [0.4979606 , 0.50304794],\n",
       "         [0.500086  , 0.5012785 ],\n",
       "         [0.5014246 , 0.49905044]],\n",
       "\n",
       "        [[0.50905555, 0.50997704],\n",
       "         [0.8228859 , 0.39981169],\n",
       "         [0.42547068, 0.49378344],\n",
       "         ...,\n",
       "         [0.49985453, 0.49867627],\n",
       "         [0.5004185 , 0.49947584],\n",
       "         [0.50053936, 0.49931282]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.5102366 , 0.47178397],\n",
       "         [0.35630396, 0.4900305 ],\n",
       "         [0.52206117, 0.507384  ],\n",
       "         ...,\n",
       "         [0.49802193, 0.49814135],\n",
       "         [0.49897283, 0.5026224 ],\n",
       "         [0.49959648, 0.49933696]],\n",
       "\n",
       "        [[0.539146  , 0.46572432],\n",
       "         [0.51849765, 0.5766358 ],\n",
       "         [0.51749736, 0.47150582],\n",
       "         ...,\n",
       "         [0.5013975 , 0.49943635],\n",
       "         [0.49815455, 0.50067914],\n",
       "         [0.50080913, 0.5007642 ]],\n",
       "\n",
       "        [[0.49176958, 0.4803161 ],\n",
       "         [0.69903374, 0.6983391 ],\n",
       "         [0.4772972 , 0.46542475],\n",
       "         ...,\n",
       "         [0.49809235, 0.49847355],\n",
       "         [0.49860558, 0.50180477],\n",
       "         [0.50129807, 0.49858332]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4955548 , 0.47152692],\n",
       "         [0.549055  , 0.5021345 ],\n",
       "         [0.4842374 , 0.50417835],\n",
       "         ...,\n",
       "         [0.49825823, 0.4967973 ],\n",
       "         [0.5004969 , 0.49947497],\n",
       "         [0.50128096, 0.49978244]],\n",
       "\n",
       "        [[0.5215622 , 0.47223976],\n",
       "         [0.5645852 , 0.5173584 ],\n",
       "         [0.48305854, 0.48978445],\n",
       "         ...,\n",
       "         [0.4967222 , 0.5005758 ],\n",
       "         [0.4996508 , 0.5009681 ],\n",
       "         [0.5012732 , 0.49890316]],\n",
       "\n",
       "        [[0.5131428 , 0.50279   ],\n",
       "         [0.6311983 , 0.5582772 ],\n",
       "         [0.48242718, 0.48472983],\n",
       "         ...,\n",
       "         [0.49906674, 0.49896768],\n",
       "         [0.5001876 , 0.4994808 ],\n",
       "         [0.5005898 , 0.49938074]]],\n",
       "\n",
       "\n",
       "       [[[0.57911325, 0.6674996 ],\n",
       "         [0.38925293, 0.06719027],\n",
       "         [0.39415687, 0.40205255],\n",
       "         ...,\n",
       "         [0.49548784, 0.49824646],\n",
       "         [0.49584854, 0.49988326],\n",
       "         [0.49816605, 0.50107145]],\n",
       "\n",
       "        [[0.49541235, 0.47658998],\n",
       "         [0.5255488 , 0.5869763 ],\n",
       "         [0.530294  , 0.5015141 ],\n",
       "         ...,\n",
       "         [0.5039595 , 0.49929526],\n",
       "         [0.5009035 , 0.50253737],\n",
       "         [0.50023675, 0.5015977 ]],\n",
       "\n",
       "        [[0.49334666, 0.46902204],\n",
       "         [0.4924809 , 0.55030954],\n",
       "         [0.523105  , 0.50556177],\n",
       "         ...,\n",
       "         [0.49825224, 0.49844182],\n",
       "         [0.49987215, 0.5041801 ],\n",
       "         [0.5007271 , 0.50126284]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5077418 , 0.4840017 ],\n",
       "         [0.47798657, 0.47684819],\n",
       "         [0.4899749 , 0.50787324],\n",
       "         ...,\n",
       "         [0.499731  , 0.49757332],\n",
       "         [0.4998335 , 0.49996302],\n",
       "         [0.500838  , 0.49926254]],\n",
       "\n",
       "        [[0.52100885, 0.50175273],\n",
       "         [0.46227214, 0.4787447 ],\n",
       "         [0.5008235 , 0.49889657],\n",
       "         ...,\n",
       "         [0.49862105, 0.5017726 ],\n",
       "         [0.49953252, 0.50014246],\n",
       "         [0.50132537, 0.49977243]],\n",
       "\n",
       "        [[0.51781356, 0.5052608 ],\n",
       "         [0.46107745, 0.44798255],\n",
       "         [0.4972213 , 0.49514392],\n",
       "         ...,\n",
       "         [0.4995409 , 0.49868295],\n",
       "         [0.5006519 , 0.5000562 ],\n",
       "         [0.5006363 , 0.49936104]]],\n",
       "\n",
       "\n",
       "       [[[0.5066836 , 0.47425738],\n",
       "         [0.47446537, 0.4932402 ],\n",
       "         [0.49565023, 0.5156264 ],\n",
       "         ...,\n",
       "         [0.4965241 , 0.5003383 ],\n",
       "         [0.49804765, 0.50334674],\n",
       "         [0.49932498, 0.4995794 ]],\n",
       "\n",
       "        [[0.51975006, 0.49534082],\n",
       "         [0.50873965, 0.52612257],\n",
       "         [0.4955224 , 0.49416354],\n",
       "         ...,\n",
       "         [0.50391054, 0.50030184],\n",
       "         [0.5000602 , 0.5026874 ],\n",
       "         [0.49991786, 0.500194  ]],\n",
       "\n",
       "        [[0.5007057 , 0.50100535],\n",
       "         [0.50141406, 0.54595894],\n",
       "         [0.48693788, 0.50441545],\n",
       "         ...,\n",
       "         [0.49888396, 0.49891424],\n",
       "         [0.49826825, 0.50588983],\n",
       "         [0.5025232 , 0.49891627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.48670545, 0.47795475],\n",
       "         [0.5049035 , 0.5089951 ],\n",
       "         [0.4875311 , 0.50508714],\n",
       "         ...,\n",
       "         [0.49968052, 0.49674508],\n",
       "         [0.5005821 , 0.49921548],\n",
       "         [0.5016378 , 0.5001804 ]],\n",
       "\n",
       "        [[0.50783837, 0.48620173],\n",
       "         [0.47776428, 0.5174994 ],\n",
       "         [0.50168175, 0.49348134],\n",
       "         ...,\n",
       "         [0.49902537, 0.4990275 ],\n",
       "         [0.4983159 , 0.5010728 ],\n",
       "         [0.5008261 , 0.4984977 ]],\n",
       "\n",
       "        [[0.5018618 , 0.49276644],\n",
       "         [0.4972499 , 0.5180055 ],\n",
       "         [0.5031763 , 0.49785468],\n",
       "         ...,\n",
       "         [0.499585  , 0.49891192],\n",
       "         [0.5003885 , 0.4981181 ],\n",
       "         [0.501006  , 0.49867618]]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(x_i,x_hat):\n",
    "    x_i_real = np.reshape(x_i[:,:,:,0],(len(x_i),-1))\n",
    "    x_i_img  = np.reshape(x_i[:,:,:,1],(len(x_i),-1))\n",
    "    x_i_C = x_i_real-0.5 + 1j*(x_i_img-0.5)\n",
    "\n",
    "    x_hat_real = np.reshape(x_hat[:,:,:,0],(len(x_i),-1))\n",
    "    x_hat_img  = np.reshape(x_hat[:,:,:,1],(len(x_i),-1))\n",
    "    x_hat_C = x_hat_real-0.5 + 1j*(x_hat_img-0.5)\n",
    "\n",
    "    mse = np.mean(np.abs(x_i_C-x_hat_C)**2, axis=1)\n",
    "    power = np.sum(np.abs(x_i_C)**2, axis=1)\n",
    "    NMSE = mse/power\n",
    "    NMSE = 10*np.log10(NMSE)\n",
    "    NMSE = np.sum(NMSE)\n",
    "    return NMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE is  -756404.004370677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"NMSE is \", NMSE(x_test,x_hat)/(x_text.shape[0]))\n",
    "filename = \"result/decoded_%s.csv\"%file\n",
    "x_hat1 = np.reshape(x_hat, (len(x_hat), -1))\n",
    "np.savetxt(filename, x_hat1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tensorflow/model_CsiNet__dim512_05_26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tensorflow/model_CsiNet__dim512_05_26\\assets\n"
     ]
    }
   ],
   "source": [
    "# Serialize model to JSON\n",
    "model_json = autoencoder.to_json()\n",
    "outfile = \"result/model_%s.json\"%file\n",
    "with open(outfile, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Serialize weights to HDF5\n",
    "outfile = \"result/model_%s.h5\"%file\n",
    "autoencoder.save_weights(outfile)\n",
    "\n",
    "# Save model in tensorflow format\n",
    "autoencoder.save(\"tensorflow/model_%s\"%file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
